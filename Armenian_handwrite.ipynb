{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDYaygJjbFyJ"
      },
      "source": [
        "# Downloading dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fe56a6b7"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a269318d",
        "outputId": "f0a8895f-bbf6-4415-b509-95105636ce13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading mashtots-dataset.zip to /content\n",
            " 67% 146M/219M [00:00<00:00, 1.53GB/s]\n",
            "100% 219M/219M [00:00<00:00, 944MB/s] \n"
          ]
        }
      ],
      "source": [
        "# Now, try downloading the dataset again\n",
        "!kaggle competitions download -c mashtots-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caf7d94f",
        "outputId": "1f1d2e10-6f08-47fd-94aa-93ced7d13c63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ls: cannot access 'mashtots-dataset': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# Unzip the downloaded dataset\n",
        "!unzip -q mashtots-dataset.zip\n",
        "\n",
        "# List the contents of the extracted directory to verify\n",
        "!ls mashtots-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eimss6itn12R"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c82bd1d6"
      },
      "source": [
        "# Task\n",
        "Train a ResNet-like model for image classification using the \"mashtots-dataset.zip\", then make predictions on the \"new_test.csv\" dataset, saving the results to \"submission.csv\" and \"detailed_predictions.csv\", and generating visualizations of the predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f04a3f0b"
      },
      "source": [
        "## Kaggle Setup and Dataset Download\n",
        "\n",
        "### Subtask:\n",
        "ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹Ñ‚Ðµ ÐºÐ»ÑŽÑ‡ API Kaggle, Ð·Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚Ðµ 'mashtots-dataset.zip' Ð¸ Ñ€Ð°ÑÐ¿Ð°ÐºÑƒÐ¹Ñ‚Ðµ ÐµÐ³Ð¾ ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ð¼Ð¾Ðµ. Ð£Ð±ÐµÐ´Ð¸Ñ‚ÐµÑÑŒ, Ñ‡Ñ‚Ð¾ Ð²ÑÐµ Ð½ÐµÐ¾Ð±Ñ…Ð¾Ð´Ð¸Ð¼Ñ‹Ðµ Ñ„Ð°Ð¹Ð»Ñ‹ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚Ð° Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ‹.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a4e73ce"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous command `ls mashtots-dataset` failed, suggesting the dataset was not unzipped into a folder with that specific name. To locate the extracted dataset files, I will use `ls -F` to list all files and directories in the current working directory, which will help identify the actual root directory of the dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03a9a1dc",
        "outputId": "ddf98982-8e67-4689-aa28-e965c9f346e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "detailed_predictions.csv  mashtots_resnet.pth\t\t sample_data/\n",
            "mashtots-dataset/\t  prediction_distributions.png\t submission.csv\n",
            "mashtots-dataset.zip\t  predictions_visualization.png  Test_sample/\n"
          ]
        }
      ],
      "source": [
        "!\n",
        "\n",
        "# List all contents of the current directory to find the extracted dataset\n",
        "!ls -F\n",
        "\n",
        "# Based on the output, identify the folder containing 'Train', 'new_test', etc.\n",
        "# For example, if you see 'Train/' directly, then '.' is the root. If you see 'mashtots-dataset-unzipped/', then that's the root.\n",
        "# You might need to adjust the 'root' variable in the training code based on this discovery."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b57cf77d"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous output showed that a directory named `mashtots-dataset/` was created. To fully confirm that the unzipping was successful and the necessary dataset files (`Train/`, `new_test/`, `sample_submission.csv`) are present, I need to list the contents of this specific directory.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5459814",
        "outputId": "97e3736d-322a-4abb-8542-c80acfc95392"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "new_test/  sample_submission.csv  Train/\n"
          ]
        }
      ],
      "source": [
        "!\n",
        "!ls -F mashtots-dataset/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06f74f49"
      },
      "source": [
        "## Import Libraries and Define Configuration\n",
        "\n",
        "### Subtask:\n",
        "Ð˜Ð¼Ð¿Ð¾Ñ€Ñ‚Ð¸Ñ€ÑƒÐ¹Ñ‚Ðµ Ð²ÑÐµ Ð½ÐµÐ¾Ð±Ñ…Ð¾Ð´Ð¸Ð¼Ñ‹Ðµ Ð±Ð¸Ð±Ð»Ð¸Ð¾Ñ‚ÐµÐºÐ¸ Python (torch, numpy, pandas, matplotlib, cv2, albumentations Ð¸ Ñ‚.Ð´.). ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»Ð¸Ñ‚Ðµ Ð³Ð»Ð¾Ð±Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¸, Ñ‚Ð°ÐºÐ¸Ðµ ÐºÐ°Ðº 'IMG_SIZE', 'NUM_CLASSES', 'BATCH_SIZE', 'EPOCHS', 'LR' Ð¸ 'DEVICE'.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25e834c1"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires importing several libraries and defining global configuration parameters. This can be accomplished with a single Python code block.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "f64090d0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import random\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5i52_-iKpzoP"
      },
      "source": [
        "Train test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYos1MRDpyr5",
        "outputId": "74f75309-8116-48a7-a1f4-a71d5d253a31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ð“Ð¾Ñ‚Ð¾Ð²Ð¾! Ð¤Ð°Ð¹Ð»Ñ‹ Ð¿ÐµÑ€ÐµÐ¼ÐµÑ‰ÐµÐ½Ñ‹.\n"
          ]
        }
      ],
      "source": [
        "train_dir = 'mashtots-dataset/Train'\n",
        "test_dir = 'mashtots-dataset/Test'\n",
        "\n",
        "percentage = 20\n",
        "\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "for class_name in os.listdir(train_dir):\n",
        "    train_class_path = os.path.join(train_dir, class_name)\n",
        "    test_class_path = os.path.join(test_dir, class_name)\n",
        "\n",
        "    if os.path.isdir(train_class_path):\n",
        "        os.makedirs(test_class_path, exist_ok=True)\n",
        "\n",
        "        files = os.listdir(train_class_path)\n",
        "        random.shuffle(files)\n",
        "\n",
        "        n_files = int(len(files) * (percentage / 100))\n",
        "\n",
        "        selected_files = files[:n_files]\n",
        "\n",
        "        for file_name in selected_files:\n",
        "            src_path = os.path.join(train_class_path, file_name)\n",
        "            dst_path = os.path.join(test_class_path, file_name)\n",
        "            shutil.move(src_path, dst_path)\n",
        "\n",
        "print(\"Ð“Ð¾Ñ‚Ð¾Ð²Ð¾! Ð¤Ð°Ð¹Ð»Ñ‹ Ð¿ÐµÑ€ÐµÐ¼ÐµÑ‰ÐµÐ½Ñ‹.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9gOVd0Ke0jC"
      },
      "source": [
        "Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "oGW7UFHEe2Lm"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = 64\n",
        "NUM_CLASSES = 78\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 30\n",
        "LR = 1e-3\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "554cb260"
      },
      "source": [
        "## Define Model Architecture\n",
        "\n",
        "### Subtask:\n",
        "ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»Ð¸Ñ‚Ðµ ÐºÐ»Ð°ÑÑÑ‹ 'ResidualBlock' Ð¸ 'MashtotsResNet' Ð² Ñ‚Ð¾Ñ‡Ð½Ð¾ÑÑ‚Ð¸, ÐºÐ°Ðº Ð¾Ð½Ð¸ Ð±Ñ‹Ð»Ð¸ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ñ‹ Ð² ÑÐºÑ€Ð¸Ð¿Ñ‚Ðµ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cf3a006"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires defining the `ResidualBlock` and `MashtotsResNet` classes as they were in the training script. I will extract these class definitions from the initial setup code block.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ed31214f",
        "outputId": "10d13088-af0a-4551-d729-2e277bf1507d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model architecture (ResidualBlock and MashtotsResNet) defined.\n"
          ]
        }
      ],
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, stride=1):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_ch, out_ch, 3, stride, 1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_ch)\n",
        "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, 1, 1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_ch)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_ch != out_ch:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_ch, out_ch, 1, stride, bias=False),\n",
        "                nn.BatchNorm2d(out_ch)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        return F.relu(out)\n",
        "\n",
        "class MashtotsResNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layer1 = ResidualBlock(1, 64)\n",
        "        self.layer2 = ResidualBlock(64, 128, stride=2)\n",
        "        self.layer3 = ResidualBlock(128, 256, stride=2)\n",
        "        self.layer4 = ResidualBlock(256, 512, stride=2)\n",
        "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Linear(512, NUM_CLASSES)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.pool(x).squeeze(-1).squeeze(-1)\n",
        "        return self.fc(x)\n",
        "\n",
        "print(\"Model architecture (ResidualBlock and MashtotsResNet) defined.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb58b726"
      },
      "source": [
        "## Prepare Training and Validation Datasets\n",
        "\n",
        "### Subtask:\n",
        "ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»Ð¸Ñ‚Ðµ ÐºÐ»Ð°ÑÑ 'MashtotsDataset'. Ð—Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚Ðµ Ñ‚Ñ€ÐµÐ½Ð¸Ñ€Ð¾Ð²Ð¾Ñ‡Ð½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ, Ñ€Ð°Ð·Ð´ÐµÐ»Ð¸Ñ‚Ðµ Ð¸Ñ… Ð½Ð° Ñ‚Ñ€ÐµÐ½Ð¸Ñ€Ð¾Ð²Ð¾Ñ‡Ð½Ñ‹Ð¹ Ð¸ Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ð¾Ð½Ð½Ñ‹Ð¹ Ð½Ð°Ð±Ð¾Ñ€Ñ‹, Ð° Ð·Ð°Ñ‚ÐµÐ¼ ÑÐ¾Ð·Ð´Ð°Ð¹Ñ‚Ðµ 'DataLoader'Ñ‹' Ð´Ð»Ñ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð¸ Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ð¸, Ð²ÐºÐ»ÑŽÑ‡Ð°Ñ Ð°ÑƒÐ³Ð¼ÐµÐ½Ñ‚Ð°Ñ†Ð¸ÑŽ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð»Ñ Ñ‚Ñ€ÐµÐ½Ð¸Ñ€Ð¾Ð²Ð¾Ñ‡Ð½Ð¾Ð³Ð¾ Ð½Ð°Ð±Ð¾Ñ€Ð°.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3c5d2833"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires defining the `MashtotsDataset` class, preparing the training and validation datasets by splitting indices, and creating `DataLoader` instances for both, including data augmentation for the training set. This can be done in a single code block by extracting the relevant sections from the original notebook.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "900476ec"
      },
      "outputs": [],
      "source": [
        "class MashtotsDataset(Dataset):\n",
        "    def __init__(self, root_dir, indices, augment=False):\n",
        "        self.samples = []\n",
        "        self.augment = augment\n",
        "\n",
        "        for folder in os.listdir(root_dir):\n",
        "            folder_path = os.path.join(root_dir, folder)\n",
        "            if not os.path.isdir(folder_path):\n",
        "                continue\n",
        "\n",
        "            label = int(folder)\n",
        "            for file in os.listdir(folder_path):\n",
        "                self.samples.append((os.path.join(folder_path, file), label))\n",
        "\n",
        "        self.samples = [self.samples[i] for i in indices]\n",
        "\n",
        "        self.transform = A.Compose([\n",
        "            A.Rotate(limit=10, p=0.5),\n",
        "            A.ShiftScaleRotate(0.05, 0.1, 10, p=0.5),\n",
        "            A.GaussianBlur(blur_limit=3, p=0.3),\n",
        "            A.RandomBrightnessContrast(0.2, 0.2, p=0.5),\n",
        "            A.Normalize(mean=(0.5,), std=(0.5,)),\n",
        "            ToTensorV2()\n",
        "        ]) if augment else A.Compose([\n",
        "            A.Normalize(mean=(0.5,), std=(0.5,)),\n",
        "            ToTensorV2()\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path, label = self.samples[idx]\n",
        "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
        "        img = self.transform(image=img)[\"image\"]\n",
        "        return img, label\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MO9cs2HXgw85"
      },
      "source": [
        "Preaper data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgzdomYTgzRl",
        "outputId": "c4543ead-f8fe-41c1-bc50-85fc6b3c96be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MashtotsDataset class defined and DataLoaders for training and validation prepared.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
            "  original_init(self, **validated_kwargs)\n"
          ]
        }
      ],
      "source": [
        "root = \"mashtots-dataset/Train\"\n",
        "\n",
        "all_indices = list(range(sum(len(files) for _, _, files in os.walk(root))))\n",
        "train_idx, val_idx = train_test_split(all_indices, test_size=0.2, random_state=42)\n",
        "\n",
        "train_ds = MashtotsDataset(root, train_idx, augment=True)\n",
        "val_ds = MashtotsDataset(root, val_idx, augment=False)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "\n",
        "print(\"MashtotsDataset class defined and DataLoaders for training and validation prepared.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8t2kCVNXhZ5"
      },
      "source": [
        "Architecture of model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "DtQQtVZuXgOt"
      },
      "outputs": [],
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, stride=1, groups=8):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_ch, out_ch, kernel_size=3,\n",
        "                               stride=stride, padding=1, bias=False)\n",
        "        self.gn1 = nn.GroupNorm(groups, out_ch)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(out_ch, out_ch, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.gn2 = nn.GroupNorm(groups, out_ch)\n",
        "\n",
        "        self.shortcut = nn.Identity()\n",
        "        if stride != 1 or in_ch != out_ch:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_ch, out_ch, kernel_size=1,\n",
        "                          stride=stride, bias=False),\n",
        "                nn.GroupNorm(groups, out_ch)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.gn1(self.conv1(x)), inplace=True)\n",
        "        out = self.gn2(self.conv2(out))\n",
        "        out = out + self.shortcut(x)\n",
        "        return F.relu(out, inplace=True)\n",
        "\n",
        "\n",
        "class MashtotsResNet(nn.Module):\n",
        "    def __init__(self, num_classes=NUM_CLASSES):\n",
        "        super().__init__()\n",
        "\n",
        "        # stem (Ð¾Ñ‡ÐµÐ½ÑŒ Ð¿Ð¾Ð¼Ð¾Ð³Ð°ÐµÑ‚ ÑÑ‚Ð°Ð±Ð¸Ð»ÑŒÐ½Ð¾ÑÑ‚Ð¸)\n",
        "        self.stem = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.GroupNorm(8, 64),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.layer1 = ResidualBlock(64, 64)\n",
        "        self.layer2 = ResidualBlock(64, 128, stride=2)\n",
        "        self.layer3 = ResidualBlock(128, 256, stride=2)\n",
        "        self.layer4 = ResidualBlock(256, 512, stride=2)\n",
        "\n",
        "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Linear(512, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.pool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        return self.fc(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VOWE8ReXnVA"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rTwBsKUXp2R",
        "outputId": "75d78417-f767-421f-bf0f-b290cf796bc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/30] | Train: 3.90% | Val: 11.26%\n",
            "Epoch [2/30] | Train: 44.45% | Val: 74.43%\n",
            "Epoch [3/30] | Train: 78.50% | Val: 85.47%\n",
            "Epoch [4/30] | Train: 85.58% | Val: 88.62%\n",
            "Epoch [5/30] | Train: 87.73% | Val: 89.55%\n",
            "Epoch [6/30] | Train: 89.22% | Val: 91.31%\n",
            "Epoch [7/30] | Train: 90.43% | Val: 90.66%\n",
            "Epoch [8/30] | Train: 91.08% | Val: 91.29%\n",
            "Epoch [9/30] | Train: 91.67% | Val: 92.14%\n",
            "Epoch [10/30] | Train: 92.20% | Val: 92.60%\n",
            "Epoch [11/30] | Train: 92.70% | Val: 92.84%\n",
            "Epoch [12/30] | Train: 93.01% | Val: 92.37%\n",
            "Epoch [13/30] | Train: 93.32% | Val: 93.03%\n",
            "Epoch [14/30] | Train: 93.89% | Val: 93.04%\n",
            "Epoch [15/30] | Train: 94.28% | Val: 93.59%\n",
            "Epoch [16/30] | Train: 94.49% | Val: 93.74%\n",
            "Epoch [17/30] | Train: 94.98% | Val: 94.09%\n",
            "Epoch [18/30] | Train: 95.38% | Val: 94.13%\n",
            "Epoch [19/30] | Train: 95.72% | Val: 94.37%\n",
            "Epoch [20/30] | Train: 95.80% | Val: 94.19%\n",
            "Epoch [21/30] | Train: 96.26% | Val: 94.48%\n",
            "Epoch [22/30] | Train: 96.47% | Val: 94.51%\n",
            "Epoch [23/30] | Train: 96.56% | Val: 94.52%\n",
            "Epoch [24/30] | Train: 96.83% | Val: 94.59%\n",
            "Epoch [25/30] | Train: 97.01% | Val: 94.61%\n",
            "Epoch [26/30] | Train: 97.18% | Val: 94.75%\n",
            "Epoch [27/30] | Train: 97.28% | Val: 94.69%\n",
            "Epoch [28/30] | Train: 97.39% | Val: 94.70%\n",
            "Epoch [29/30] | Train: 97.50% | Val: 94.70%\n",
            "Epoch [30/30] | Train: 97.41% | Val: 94.73%\n"
          ]
        }
      ],
      "source": [
        "model = MashtotsResNet().to(DEVICE)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, EPOCHS)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    correct, total = 0, 0\n",
        "    for x, y in train_loader:\n",
        "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(x)\n",
        "        loss = criterion(out, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        _, pred = out.max(1)\n",
        "        correct += pred.eq(y).sum().item()\n",
        "        total += y.size(0)\n",
        "\n",
        "    train_acc = 100 * correct / total\n",
        "\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in val_loader:\n",
        "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "            out = model(x)\n",
        "            _, pred = out.max(1)\n",
        "            correct += pred.eq(y).sum().item()\n",
        "            total += y.size(0)\n",
        "\n",
        "    val_acc = 100 * correct / total\n",
        "    scheduler.step()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{EPOCHS}] | Train: {train_acc:.2f}% | Val: {val_acc:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSK1e8j7XsGX"
      },
      "source": [
        "Saving Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0Ws23u0XraI",
        "outputId": "f75ff430-28ca-42ec-dfbb-853d6448e004"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ”¥ Model saved\n"
          ]
        }
      ],
      "source": [
        "torch.save(model.state_dict(), \"mashtots_resnet.pth\")\n",
        "print(\"ðŸ”¥ Model saved\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hj4SXPEfXxR4"
      },
      "source": [
        "# **TESTING**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTIoYdi7X2R9"
      },
      "source": [
        "# Prepearing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "EOFB2Ki7X1TZ"
      },
      "outputs": [],
      "source": [
        "root = \"mashtots-dataset/Test\"\n",
        "\n",
        "all_indices = list(range(sum(len(files) for _, _, files in os.walk(root))))\n",
        "\n",
        "test_ds = MashtotsDataset(root, all_indices, augment=True)\n",
        "\n",
        "test_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xo-q4IPhhnIV"
      },
      "source": [
        "# Loading model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQqvj1KVhrp5",
        "outputId": "4271b2b2-7750-462b-d016-e8978f119caf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MashtotsResNet(\n",
              "  (stem): Sequential(\n",
              "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (1): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "  )\n",
              "  (layer1): ResidualBlock(\n",
              "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (gn1): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
              "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (gn2): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
              "    (shortcut): Identity()\n",
              "  )\n",
              "  (layer2): ResidualBlock(\n",
              "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (gn1): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
              "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (gn2): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
              "    (shortcut): Sequential(\n",
              "      (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "      (1): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): ResidualBlock(\n",
              "    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (gn1): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
              "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (gn2): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
              "    (shortcut): Sequential(\n",
              "      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "      (1): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): ResidualBlock(\n",
              "    (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (gn1): GroupNorm(8, 512, eps=1e-05, affine=True)\n",
              "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (gn2): GroupNorm(8, 512, eps=1e-05, affine=True)\n",
              "    (shortcut): Sequential(\n",
              "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "      (1): GroupNorm(8, 512, eps=1e-05, affine=True)\n",
              "    )\n",
              "  )\n",
              "  (pool): AdaptiveAvgPool2d(output_size=1)\n",
              "  (fc): Linear(in_features=512, out_features=78, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = MashtotsResNet().to(DEVICE)\n",
        "model.load_state_dict(torch.load(\"mashtots_resnet.pth\"))\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sW-fR1KhwnT"
      },
      "source": [
        "# Doing predicition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUpoO_IxhRx6",
        "outputId": "d4246a06-56e9-48c9-88b7-8cd76e159f9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean confidence: 0.762\n",
            "Correct mean confidence: 0.825\n",
            "Wrong mean confidence: 0.582\n"
          ]
        }
      ],
      "source": [
        "def tta_predict(model, x):\n",
        "    preds = []\n",
        "\n",
        "    preds.append(model(x))\n",
        "    preds.append(model(torch.flip(x, dims=[3])))  # horizontal flip\n",
        "\n",
        "    return torch.mean(torch.stack(preds), dim=0)\n",
        "\n",
        "\n",
        "confidences = []\n",
        "correct_flags = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x, y in test_loader:\n",
        "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "\n",
        "        out = tta_predict(model, x)\n",
        "        probs = F.softmax(out, dim=1)\n",
        "        conf, pred = probs.max(dim=1)\n",
        "\n",
        "        confidences.extend(conf.cpu().numpy())\n",
        "        correct_flags.extend((pred == y).cpu().numpy())\n",
        "\n",
        "confidences = np.array(confidences)\n",
        "correct_flags = np.array(correct_flags)\n",
        "\n",
        "print(f\"Mean confidence: {confidences.mean():.3f}\")\n",
        "print(f\"Correct mean confidence: {confidences[correct_flags].mean():.3f}\")\n",
        "print(f\"Wrong mean confidence: {confidences[~correct_flags].mean():.3f}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
